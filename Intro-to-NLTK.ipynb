{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of content</h1>\n",
    "\n",
    "<h4>A. Brief intro to NLP (intro and sources to learn)</h4>\n",
    "\n",
    "- What is NLP?\n",
    "- How is this done with programming?\n",
    "- What is semantic analysis?\n",
    "- How is semantic analysis useful?\n",
    "\n",
    "<h4>B. Project: Tweet sentiment analysis with NLTK:</h4>\n",
    "\n",
    "SET UP THE SENTIMENT ANALYSIS WITH NLTK and Naive Bayes classifier\n",
    "- Explain our approach\n",
    "- Install packages and explain workspace structure\n",
    "- Get the data\n",
    "- Text Classification\n",
    "- Creating Features\n",
    "- Train the dataset using Naive Bayes Classifier\n",
    "- Use the sentiment\n",
    "- Evaluation\n",
    "\n",
    "\n",
    "GET LIVE TWEETS FROM TWITTER API\n",
    "- Applying for Twitter API (tweepy)\n",
    "- Get live tweets to go through our sentiment\n",
    "- Graph live tweets using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> A. Brief intro in NLP</h1>\n",
    "\n",
    "NLP is a specialized field of computer science and artificial intelligence with roots in computational linguistics. The idea of Natural Language Processing is to do some form of analysis, or processing, where the machine can understand, at least to some level, what the text means, says, or implies.\n",
    "\n",
    "\n",
    "Ever since the digital age, there accumulated a resourseful amount of data on the internet, specifically text, which contain a wealth of information. However, due to the huge amount of text data available, among with inherent complexity in processing, there is a limit of what human can do to analyze these unstructured sources of data, which can be a potential gold mine, for example in fields from marketing to politics, where it's extremely important to know the public opinions. \n",
    "\n",
    "\n",
    "This is where programming and the work of sentiment analysis come in handy. Sentiment analysis is the extraction of sentiment - extracting whether a product review is oriented towards positive, negative, or neutral, whether an email is spam, not spam, or important. Feel free to take the time to think of other sentiment extraction applications you might have come accross in your daily life.\n",
    "\n",
    "\n",
    "The simplest version of sentiment analysis is a binary classification task, <i>classify</i> whether a piece of texts is expressing a positive or a negative opinion. Consider a review towards moviews, words like <i>great, boring, wonderful, mediocre </i> are extremely helpful for hinting about where this review is going. \n",
    "\n",
    "\n",
    "Imagine, if we have an enough amount of these informative words, labeled with their classification, such as: ('great', 'positive'), ('boring', negative), ('wonderful', 'positive'), we could just tell the computer to help us save these info and calculate the possibility if a review 'I'm so bored I could't finish the whole thing' is positive or negative? This is exactly what we are attempting to do in this tutorial.\n",
    "\n",
    "\n",
    "But now first, lets review the standard process of a NLP project to have a hint of what we'll be going through:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NLP workflow](https://miro.medium.com/max/1000/1*BiVCmiQtCBIdBNcaOKjurg.png)\n",
    "\n",
    "<i> source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72 </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you love this topic, here are some great resouces I found super helpful for us beginners: \n",
    "- 1 entry project: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "\n",
    "- A tutorial series: https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/\n",
    "\n",
    "- Linguistics crash course: (video series) https://www.youtube.com/watch?v=eDop3FDoUzk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>B. Project: Tweet sentiment analysis with NLTK:</h1>\n",
    "\n",
    "As stated above, we're gonna build a binary sentiment analysis, a basic one. Our module will be able to extract the sentiment of a sentence or a small graph of text, and decide if it's positive (classification: pos) or negative (classification: neg). \n",
    "    \n",
    "Next, we get live tweets (how exciting!), let those tweets run through our module and at the same time, how about visualizing the tweet pos/neg trend through a live graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EXPLAIN OUR APPROACH</h3>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be given a labeled dataset of 10,000 positive and negative movie reviews. \n",
    "\n",
    "With each category (positive or negative), we'll break it into a bag-of-words. There'll be 2 bags total, 1 positive 1 negative, that are bot an unordered set of words, keeping only the frequency in the document, and their positions are ignored for now.\n",
    "\n",
    "![NLP bags-of-words](https://northeastern-my.sharepoint.com/:i:/r/personal/pham_phuon_northeastern_edu/Documents/nlp-intro-pics/bags-of-words.png?csf=1&web=1&e=Lrwihd)\n",
    "\n",
    "<i> source: https://web.stanford.edu/~jurafsky/slp3/4.pdf </i>\n",
    "\n",
    "We'll choose mark the most imformative words, and send the whole thing through the  Naive Bayes Classifier for module training. The Classifier basically will help us check if they are in pos or neg or both. If a word appears significantly more in a category, it's very likely the word is very critical for that category. We'll use that for our prediction.\n",
    "\n",
    "Alright, let's get to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Install things and introduce file structure</h3>  \n",
    "\n",
    "Obviously, we'll use Python for this.\n",
    "\n",
    "The following modules will be needed: Jupyter, Matplotlib, NLTK.\n",
    "\n",
    "Usually, a command line { pip install jupyterlab nltk matplotlib } or { pip3 install jupyterlab nltk matplotlib } will do.\n",
    "\n",
    "If it doesn't work for you, please refer to the installation guides:\n",
    "- jupyterlab: https://jupyter.org/install\n",
    "- nltk: https://www.nltk.org/install.html\n",
    "- matplotlib: https://matplotlib.org/users/installing.html\n",
    "\n",
    "And here's a brief introduction of our file structure:\n",
    "\n",
    "- intro-nltk.ipynb : We use this Jupyter notebook to explore the dataset, set up features and train our model.\n",
    "- sentiment.py : Our trained model will be saved in here. This will act as a module, so that we could import it and use in other projects. \n",
    "- stream.py : The code to connect to twitter API. This will run constantly as we stream live tweets in.\n",
    "- graph.py : The code for graphing. This file will also be running parallel with stream.py to graph the trend of live tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, ready to pack our bags of words?\n",
    "\n",
    "In your working folder, open jupyternotebook and create a new file. Let's call it <b>intro-nltk.ipynb</b> and import nltk to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get the data</h3>  \n",
    "\n",
    "I mentioned we are given a labeled dataset. Yes, here you go: https://northeastern-my.sharepoint.com/:f:/g/personal/pham_phuon_northeastern_edu/Ep1e6LFSz6tAk95KQKmZz-sBFux8oYSOtggonMRSU1kOUg?e=U6JTTy\n",
    "\n",
    "In your working folder, create a folder called \"dataset\" and put those files in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_pos = open(\"dataset/positive.txt\", \"r\").read()\n",
    "short_neg = open(\"dataset/negative.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text Classification</h3>\n",
    "\n",
    "The goals here are to:\n",
    "- Set up the dataset or featuresets for training and testing: collect all reviews, each review needs to be marked with either \"pos\" or \"neg\"\n",
    "- Prep for feature selection: pick out the most 5000 repeated words.\n",
    "\n",
    "Let's first create empty variables as holders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#a list of tuples. Each tuple contains the actual review and the label, for example: (\"This is a nice movie\", \"pos\")\n",
    "documents = []\n",
    "\n",
    "#all single words in our dataset\n",
    "all_words = [] \n",
    "\n",
    "#Filter only Adjectives\n",
    "allowed_word_types = [\"J\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: here I chose to use Adjectives only, but feel free to combine with other types of words, like \"N\" for nouns, \"V\" for verb; or just delete the filter and take all word types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "for p in short_pos.split(\"\\n\"):\n",
    "    documents.append( (p, \"pos\") )\n",
    "    words = nltk.word_tokenize(p) #break into words only\n",
    "    pos = nltk.pos_tag(words) #part of speeach tagging - tagging the type of the word, ex: Adjective, Verb, Noun, ...\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "            \n",
    "for n in short_neg.split(\"\\n\"):\n",
    "    documents.append((n, \"neg\"))\n",
    "    words = nltk.word_tokenize(n)\n",
    "    neg = nltk.pos_tag(words)\n",
    "    for w in neg:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10664"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "len(documents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . ',\n",
       " 'pos')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26287"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Creating Features</h3>\n",
    " \n",
    "\n",
    " Remember Zak's explanations of feature in the first meetup? They are basically characteristics of objects, so that our modules can rely on for classfication tasks. For fishes, it can be their weight, color, eye color, ... But what do we use as features in NLP, aren't there just texts? It turns out that we can do a lot with texts as features. In this project in particular, we can select the most repeated words, say 5000 words, count the frequencies, and compute as the fraction of times the word appears among all words in all documents of each topic. \n",
    " \n",
    "\n",
    "For example, \"wonderful\" is a among the top 5000 popular words. Our training spotted the word \"bad\" in 10 negative reviews, and only 1 negative review. Then if we come accross a piece of texts: \"the storyline is wonderful!\". Then it's very likely that it's a positive comment.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use nltk to find out the frequency of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 369),\n",
       " ('more', 331),\n",
       " ('little', 265),\n",
       " ('funny', 245),\n",
       " ('much', 234),\n",
       " ('bad', 234),\n",
       " ('best', 208),\n",
       " ('new', 206),\n",
       " ('own', 185),\n",
       " ('many', 183),\n",
       " ('most', 167),\n",
       " ('other', 167),\n",
       " ('great', 160),\n",
       " ('big', 156),\n",
       " ('few', 139)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#calculate the number of time a word is repeated, and put the in a dictionary.\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "#find out the most common 15 words\n",
    "all_words.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about any particular word? Just check them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "# check the amount of time a specific word appears\n",
    "all_words[\"ridiculous\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now back to our feature, lets go on pick out the most repeated 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#create a list to put those features in\n",
    "word_features = []\n",
    "for i in all_words.most_common(5000):\n",
    "    word_features.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look in there to make sure they are good stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'more',\n",
       " 'little',\n",
       " 'funny',\n",
       " 'much',\n",
       " 'bad',\n",
       " 'best',\n",
       " 'new',\n",
       " 'own',\n",
       " 'many']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "word_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, cool. Now lets find those word features and mark them within the document we are using, so that later our classifier can know that they appear in either pos or neg category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#send document in, and get returned a dictionary that confirms if the each word in the document is a feature word or not\n",
    "def find_features(document):\n",
    "    words = nltk.word_tokenize(document)\n",
    "    features = {} \n",
    "    for word in word_features:\n",
    "        features[word] = (word in words) #True/False \n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev,category) in documents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a collection of featuresets. #a list of tuples. \n",
    "Each featureset is a 2 element tuple: \n",
    "- 1 element is a dictionary returned from find_features\n",
    "- and the other element is the label: \"pos\"/\"neg\"\n",
    "\n",
    "Lets just pick one out and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'good': False,\n",
       "  'more': False,\n",
       "  'little': False,\n",
       "  'funny': False,\n",
       "  'much': False,\n",
       "  'bad': False,\n",
       "  'best': False,\n",
       "  'new': True,\n",
       "  'own': False,\n",
       "  'many': False,\n",
       "  'most': False,\n",
       "  'other': False,\n",
       "  'great': False,\n",
       "  'big': False,\n",
       "  'few': False,\n",
       "  'first': False,\n",
       "  'real': False,\n",
       "  'i': False,\n",
       "  'better': False,\n",
       "  'full': False,\n",
       "  'such': False,\n",
       "  'romantic': False,\n",
       "  'american': False,\n",
       "  'old': False,\n",
       "  'same': False,\n",
       "  'original': False,\n",
       "  'human': False,\n",
       "  'hard': False,\n",
       "  '[': False,\n",
       "  'interesting': False,\n",
       "  'young': False,\n",
       "  'enough': False,\n",
       "  'emotional': False,\n",
       "  'least': False,\n",
       "  'long': False,\n",
       "  'last': False,\n",
       "  'cinematic': False,\n",
       "  'true': False,\n",
       "  'entertaining': False,\n",
       "  'high': False,\n",
       "  'special': False,\n",
       "  'predictable': False,\n",
       "  ']': False,\n",
       "  'visual': False,\n",
       "  'familiar': False,\n",
       "  'whole': False,\n",
       "  'comic': False,\n",
       "  'enjoyable': False,\n",
       "  'sweet': False,\n",
       "  'narrative': False,\n",
       "  'less': False,\n",
       "  'short': False,\n",
       "  'worst': False,\n",
       "  'strong': False,\n",
       "  'only': False,\n",
       "  'fascinating': False,\n",
       "  'obvious': False,\n",
       "  'solid': False,\n",
       "  'powerful': False,\n",
       "  'modern': False,\n",
       "  'french': False,\n",
       "  'rare': False,\n",
       "  'fresh': False,\n",
       "  'easy': False,\n",
       "  'right': False,\n",
       "  'recent': False,\n",
       "  'next': False,\n",
       "  'dramatic': False,\n",
       "  'dull': False,\n",
       "  'worth': False,\n",
       "  'fine': False,\n",
       "  'sure': False,\n",
       "  'serious': False,\n",
       "  'black': False,\n",
       "  'beautiful': False,\n",
       "  'small': False,\n",
       "  'dark': False,\n",
       "  'hilarious': False,\n",
       "  'different': False,\n",
       "  'smart': False,\n",
       "  'sad': False,\n",
       "  'impossible': False,\n",
       "  'classic': False,\n",
       "  'compelling': False,\n",
       "  'personal': False,\n",
       "  'complex': False,\n",
       "  'psychological': False,\n",
       "  'slow': False,\n",
       "  'intelligent': False,\n",
       "  'pretentious': False,\n",
       "  'difficult': False,\n",
       "  'subject': False,\n",
       "  'flat': False,\n",
       "  'social': False,\n",
       "  'likely': False,\n",
       "  'political': False,\n",
       "  'clever': False,\n",
       "  'quirky': False,\n",
       "  'perfect': False,\n",
       "  'simple': False,\n",
       "  'silly': False,\n",
       "  'memorable': False,\n",
       "  'dumb': False,\n",
       "  'rich': False,\n",
       "  'overall': False,\n",
       "  'possible': False,\n",
       "  'several': False,\n",
       "  'second': False,\n",
       "  'final': False,\n",
       "  'excellent': False,\n",
       "  'wonderful': False,\n",
       "  'moral': False,\n",
       "  'wrong': False,\n",
       "  'thoughtful': False,\n",
       "  'entire': False,\n",
       "  'tedious': False,\n",
       "  'honest': False,\n",
       "  'nice': False,\n",
       "  'sharp': False,\n",
       "  'terrific': False,\n",
       "  'usual': False,\n",
       "  'remarkable': False,\n",
       "  'gorgeous': False,\n",
       "  'latest': False,\n",
       "  'effective': False,\n",
       "  'genuine': False,\n",
       "  'quiet': False,\n",
       "  'impressive': False,\n",
       "  'sci-fi': False,\n",
       "  'important': False,\n",
       "  'brilliant': False,\n",
       "  'stupid': False,\n",
       "  'ambitious': False,\n",
       "  'worse': False,\n",
       "  'intriguing': False,\n",
       "  'surprising': False,\n",
       "  'strange': False,\n",
       "  'able': False,\n",
       "  'clear': False,\n",
       "  'awful': False,\n",
       "  'provocative': False,\n",
       "  'sexual': False,\n",
       "  'certain': False,\n",
       "  'wild': False,\n",
       "  'historical': False,\n",
       "  'creative': False,\n",
       "  'pretty': False,\n",
       "  'decent': False,\n",
       "  'thin': False,\n",
       "  'boring': False,\n",
       "  'teen': False,\n",
       "  'major': False,\n",
       "  'deep': False,\n",
       "  'dead': False,\n",
       "  'single': False,\n",
       "  'unexpected': False,\n",
       "  'cultural': False,\n",
       "  'scary': False,\n",
       "  'unfunny': False,\n",
       "  'melodramatic': False,\n",
       "  'heavy': False,\n",
       "  'ensemble': False,\n",
       "  'coming-of-age': False,\n",
       "  'sensitive': False,\n",
       "  'previous': False,\n",
       "  'delightful': False,\n",
       "  'watchable': False,\n",
       "  'generic': False,\n",
       "  'forgettable': False,\n",
       "  'ultimate': False,\n",
       "  'old-fashioned': False,\n",
       "  'earnest': False,\n",
       "  'subtle': False,\n",
       "  'contemporary': False,\n",
       "  'happy': False,\n",
       "  'inventive': False,\n",
       "  'complete': False,\n",
       "  'successful': False,\n",
       "  'tragic': False,\n",
       "  'odd': False,\n",
       "  'considerable': False,\n",
       "  'cool': False,\n",
       "  'cold': False,\n",
       "  'white': False,\n",
       "  'low': False,\n",
       "  'tired': False,\n",
       "  'cheap': False,\n",
       "  'british': False,\n",
       "  'painful': False,\n",
       "  'female': False,\n",
       "  'urban': False,\n",
       "  'past': False,\n",
       "  'typical': False,\n",
       "  'interested': False,\n",
       "  'sentimental': False,\n",
       "  'terrible': False,\n",
       "  'crazy': False,\n",
       "  'uneven': False,\n",
       "  'stylish': False,\n",
       "  'sophisticated': False,\n",
       "  'extreme': False,\n",
       "  'fun': False,\n",
       "  'general': False,\n",
       "  'well-acted': False,\n",
       "  'gentle': False,\n",
       "  'energetic': False,\n",
       "  'witty': False,\n",
       "  'warm': False,\n",
       "  'bright': False,\n",
       "  'formulaic': False,\n",
       "  'central': False,\n",
       "  'poor': False,\n",
       "  'huge': False,\n",
       "  'utterly': False,\n",
       "  'imaginative': False,\n",
       "  'insightful': False,\n",
       "  'weak': False,\n",
       "  'tough': False,\n",
       "  'dry': False,\n",
       "  'satisfying': False,\n",
       "  'unsettling': False,\n",
       "  'conventional': False,\n",
       "  'japanese': False,\n",
       "  'derivative': False,\n",
       "  'superficial': False,\n",
       "  'pleasant': False,\n",
       "  'alive': False,\n",
       "  'unusual': False,\n",
       "  'pure': False,\n",
       "  'talented': False,\n",
       "  'minor': False,\n",
       "  'welcome': False,\n",
       "  'heavy-handed': False,\n",
       "  'unique': False,\n",
       "  'large': False,\n",
       "  'particular': False,\n",
       "  'guilty': False,\n",
       "  'light': False,\n",
       "  'worthwhile': False,\n",
       "  'weird': False,\n",
       "  'worthy': False,\n",
       "  'red': False,\n",
       "  'believable': False,\n",
       "  'simplistic': False,\n",
       "  'steven': True,\n",
       "  'greatest': False,\n",
       "  'blue': False,\n",
       "  'realistic': False,\n",
       "  'slight': False,\n",
       "  'natural': False,\n",
       "  'directorial': False,\n",
       "  'sincere': False,\n",
       "  'spiritual': False,\n",
       "  'bizarre': False,\n",
       "  'extraordinary': False,\n",
       "  'ridiculous': False,\n",
       "  'average': False,\n",
       "  'lazy': False,\n",
       "  'documentary': False,\n",
       "  'accessible': False,\n",
       "  'thought-provoking': False,\n",
       "  'poignant': False,\n",
       "  'colorful': False,\n",
       "  'manipulative': False,\n",
       "  'poetic': False,\n",
       "  'delicate': False,\n",
       "  'repetitive': False,\n",
       "  'una': False,\n",
       "  'universal': False,\n",
       "  'stunning': False,\n",
       "  'empty': False,\n",
       "  'funnier': False,\n",
       "  'dreary': False,\n",
       "  'routine': False,\n",
       "  'amazing': False,\n",
       "  'giant': False,\n",
       "  'animated': False,\n",
       "  'intense': False,\n",
       "  'free': False,\n",
       "  'admirable': False,\n",
       "  'musical': False,\n",
       "  'necessary': False,\n",
       "  'screen': False,\n",
       "  'cute': False,\n",
       "  'raw': False,\n",
       "  'artistic': False,\n",
       "  'main': False,\n",
       "  'green': False,\n",
       "  'offensive': False,\n",
       "  'national': False,\n",
       "  'deeper': False,\n",
       "  'fair': False,\n",
       "  'spectacular': False,\n",
       "  'superior': False,\n",
       "  'precious': False,\n",
       "  'well-made': False,\n",
       "  'first-time': False,\n",
       "  'chinese': False,\n",
       "  'authentic': False,\n",
       "  'unpleasant': False,\n",
       "  'grand': False,\n",
       "  'broad': False,\n",
       "  'modest': False,\n",
       "  'funniest': False,\n",
       "  'humorous': False,\n",
       "  'sappy': False,\n",
       "  'commercial': False,\n",
       "  'un': False,\n",
       "  'outrageous': False,\n",
       "  'digital': False,\n",
       "  'loud': False,\n",
       "  'standard': False,\n",
       "  'playful': False,\n",
       "  'dangerous': False,\n",
       "  'gritty': False,\n",
       "  'common': False,\n",
       "  'foreign': False,\n",
       "  'italian': False,\n",
       "  'philosophical': False,\n",
       "  'touching': False,\n",
       "  'fantastic': False,\n",
       "  'engaging': False,\n",
       "  'cynical': False,\n",
       "  'cautionary': False,\n",
       "  'exciting': False,\n",
       "  'hot': False,\n",
       "  'sloppy': False,\n",
       "  'self-indulgent': False,\n",
       "  'lame': False,\n",
       "  'tiresome': False,\n",
       "  'low-key': False,\n",
       "  'willing': False,\n",
       "  'eccentric': False,\n",
       "  'iranian': False,\n",
       "  'preposterous': False,\n",
       "  'feel-good': False,\n",
       "  'technical': False,\n",
       "  'likable': False,\n",
       "  'safe': False,\n",
       "  'close': False,\n",
       "  'b-movie': False,\n",
       "  'clumsy': False,\n",
       "  'middle': False,\n",
       "  'intellectual': False,\n",
       "  'over-the-top': False,\n",
       "  'visceral': False,\n",
       "  'utter': False,\n",
       "  'literary': False,\n",
       "  'shallow': False,\n",
       "  'real-life': False,\n",
       "  'nasty': False,\n",
       "  'unlikely': False,\n",
       "  'disappointing': False,\n",
       "  'capable': False,\n",
       "  'amusing': False,\n",
       "  'early': False,\n",
       "  'comedic': False,\n",
       "  'older': False,\n",
       "  'horrible': False,\n",
       "  'banal': False,\n",
       "  'ludicrous': False,\n",
       "  'ordinary': False,\n",
       "  'biggest': False,\n",
       "  'mediocre': False,\n",
       "  'evocative': False,\n",
       "  'thoroughly': False,\n",
       "  'michael': False,\n",
       "  'traditional': False,\n",
       "  'desperate': False,\n",
       "  'lovely': False,\n",
       "  'lyrical': False,\n",
       "  'sexy': False,\n",
       "  'vivid': False,\n",
       "  'elegant': False,\n",
       "  'sick': False,\n",
       "  'suspenseful': False,\n",
       "  'current': False,\n",
       "  'subversive': False,\n",
       "  'false': False,\n",
       "  'self-conscious': False,\n",
       "  'tasty': False,\n",
       "  'total': False,\n",
       "  'southern': False,\n",
       "  'popcorn': False,\n",
       "  'um': False,\n",
       "  'due': False,\n",
       "  'bigger': False,\n",
       "  'basic': False,\n",
       "  'overwrought': False,\n",
       "  'straight': False,\n",
       "  'amateurish': False,\n",
       "  'pathetic': False,\n",
       "  'fatal': False,\n",
       "  'lousy': False,\n",
       "  'uninspired': False,\n",
       "  'mindless': False,\n",
       "  'o': False,\n",
       "  'mixed': False,\n",
       "  'lead': False,\n",
       "  'greek': False,\n",
       "  'david': False,\n",
       "  'surreal': False,\n",
       "  'bold': False,\n",
       "  'brutal': False,\n",
       "  'finest': False,\n",
       "  'shot': False,\n",
       "  'profound': False,\n",
       "  'bitter': False,\n",
       "  'loose': False,\n",
       "  'wacky': False,\n",
       "  'public': False,\n",
       "  'spy': False,\n",
       "  'violent': False,\n",
       "  'adolescent': False,\n",
       "  'fable': False,\n",
       "  'frustrating': False,\n",
       "  'third': False,\n",
       "  'quick': False,\n",
       "  'artificial': False,\n",
       "  'unfaithful': False,\n",
       "  'evil': False,\n",
       "  'low-budget': False,\n",
       "  'graphic': False,\n",
       "  'inoffensive': False,\n",
       "  'apparent': False,\n",
       "  'chaotic': False,\n",
       "  'after-school': False,\n",
       "  'unintentional': False,\n",
       "  'famous': False,\n",
       "  'top': False,\n",
       "  'static': False,\n",
       "  'distinctive': False,\n",
       "  'significant': False,\n",
       "  'imax': False,\n",
       "  'secret': False,\n",
       "  'charming': False,\n",
       "  'stand-up': False,\n",
       "  'charismatic': False,\n",
       "  'uncompromising': False,\n",
       "  'mild': False,\n",
       "  'good-natured': False,\n",
       "  'english': False,\n",
       "  'christian': False,\n",
       "  'art': False,\n",
       "  'goofy': False,\n",
       "  'credible': False,\n",
       "  'actual': False,\n",
       "  'open': False,\n",
       "  'twisted': False,\n",
       "  'equal': False,\n",
       "  'depressing': False,\n",
       "  'present': False,\n",
       "  'ingenious': False,\n",
       "  'busy': False,\n",
       "  'afraid': False,\n",
       "  'que': False,\n",
       "  'saturday': False,\n",
       "  'awkward': False,\n",
       "  'domestic': False,\n",
       "  'slick': False,\n",
       "  'private': False,\n",
       "  'collateral': False,\n",
       "  'overlong': False,\n",
       "  'theatrical': False,\n",
       "  'constant': False,\n",
       "  'intimate': False,\n",
       "  'whimsical': False,\n",
       "  'exploitative': False,\n",
       "  'dysfunctional': False,\n",
       "  'late': False,\n",
       "  'various': False,\n",
       "  'abstract': False,\n",
       "  'flashy': False,\n",
       "  'mere': False,\n",
       "  'obnoxious': False,\n",
       "  'brown': False,\n",
       "  'adam': False,\n",
       "  'incoherent': False,\n",
       "  'ballistic': False,\n",
       "  'choppy': False,\n",
       "  'soggy': False,\n",
       "  'unnecessary': False,\n",
       "  'independent': False,\n",
       "  'masterful': False,\n",
       "  'spooky': False,\n",
       "  'snow': False,\n",
       "  'potential': False,\n",
       "  'fierce': False,\n",
       "  'detailed': False,\n",
       "  'resonant': False,\n",
       "  'key': False,\n",
       "  'russian': False,\n",
       "  'potent': False,\n",
       "  'harmless': False,\n",
       "  'irish': False,\n",
       "  'marvelous': False,\n",
       "  'faithful': False,\n",
       "  'understated': False,\n",
       "  'impeccable': False,\n",
       "  'unsentimental': False,\n",
       "  'soft': False,\n",
       "  'writer-director': False,\n",
       "  'undeniable': False,\n",
       "  'savvy': False,\n",
       "  'middle-aged': False,\n",
       "  'sensual': False,\n",
       "  'intricate': False,\n",
       "  'vibrant': False,\n",
       "  'splendid': False,\n",
       "  'larger': False,\n",
       "  'mean': False,\n",
       "  'delicious': False,\n",
       "  'ya-ya': False,\n",
       "  'thematic': False,\n",
       "  'inspirational': False,\n",
       "  'sour': False,\n",
       "  'vital': False,\n",
       "  'noble': False,\n",
       "  'hopeful': False,\n",
       "  'promising': False,\n",
       "  'satirical': False,\n",
       "  'casual': False,\n",
       "  'physical': False,\n",
       "  'grim': False,\n",
       "  'fanciful': False,\n",
       "  'younger': False,\n",
       "  'bleak': False,\n",
       "  'creepy': False,\n",
       "  'mainstream': False,\n",
       "  'frank': False,\n",
       "  'like': False,\n",
       "  'unfocused': False,\n",
       "  'critical': False,\n",
       "  'substantial': False,\n",
       "  'hackneyed': False,\n",
       "  'joyous': False,\n",
       "  'ponderous': False,\n",
       "  'professional': False,\n",
       "  'robert': False,\n",
       "  'half': False,\n",
       "  'trite': False,\n",
       "  'endless': False,\n",
       "  'well-intentioned': False,\n",
       "  'feature-length': False,\n",
       "  'stale': False,\n",
       "  'leaden': False,\n",
       "  'unimaginative': False,\n",
       "  'gross-out': False,\n",
       "  'elaborate': False,\n",
       "  'asian': False,\n",
       "  'el': False,\n",
       "  'inner': False,\n",
       "  'refreshing': False,\n",
       "  'respectable': False,\n",
       "  'aware': False,\n",
       "  'careful': False,\n",
       "  'unflinching': False,\n",
       "  'positive': False,\n",
       "  'messy': False,\n",
       "  'striking': False,\n",
       "  'easier': False,\n",
       "  'brief': False,\n",
       "  'unnerving': False,\n",
       "  'notorious': False,\n",
       "  'super': False,\n",
       "  'uncertain': False,\n",
       "  'south': False,\n",
       "  'stylistic': False,\n",
       "  'serviceable': False,\n",
       "  'divine': False,\n",
       "  'religious': False,\n",
       "  'gripping': False,\n",
       "  'run-of-the-mill': False,\n",
       "  'inconsequential': False,\n",
       "  'popular': False,\n",
       "  'outstanding': False,\n",
       "  'extended': False,\n",
       "  'sympathetic': False,\n",
       "  'hollow': False,\n",
       "  'mysterious': False,\n",
       "  'well-crafted': False,\n",
       "  'european': False,\n",
       "  'exceptional': False,\n",
       "  'comfortable': False,\n",
       "  'hip-hop': False,\n",
       "  'curious': False,\n",
       "  'male': False,\n",
       "  'running': False,\n",
       "  'inept': False,\n",
       "  'downright': False,\n",
       "  'uneasy': False,\n",
       "  'unpredictable': False,\n",
       "  'convincing': False,\n",
       "  'longer': False,\n",
       "  'limited': False,\n",
       "  'exquisite': False,\n",
       "  'indian': False,\n",
       "  'broken': False,\n",
       "  'supernatural': False,\n",
       "  'gay': False,\n",
       "  'problematic': False,\n",
       "  'pedestrian': False,\n",
       "  'plain': False,\n",
       "  'improbable': False,\n",
       "  'inevitable': False,\n",
       "  'similar': False,\n",
       "  'unoriginal': False,\n",
       "  'devoid': False,\n",
       "  'disposable': False,\n",
       "  'lackluster': False,\n",
       "  'laughable': False,\n",
       "  'implausible': False,\n",
       "  'miserable': False,\n",
       "  'greater': True,\n",
       "  'snappy': False,\n",
       "  'incisive': False,\n",
       "  'earlier': False,\n",
       "  'hugh': False,\n",
       "  'literate': False,\n",
       "  'darkly': False,\n",
       "  'disturbing': False,\n",
       "  'accomplished': False,\n",
       "  'korean': False,\n",
       "  'infectious': False,\n",
       "  'innocent': False,\n",
       "  'well-meaning': False,\n",
       "  'jewish': False,\n",
       "  'harsh': False,\n",
       "  'unforgettable': False,\n",
       "  'claustrophobic': False,\n",
       "  'dong': False,\n",
       "  'polished': False,\n",
       "  'peculiar': False,\n",
       "  'occasional': False,\n",
       "  'gross': False,\n",
       "  'legendary': False,\n",
       "  'enormous': False,\n",
       "  'rough': False,\n",
       "  'soulful': False,\n",
       "  'attal': False,\n",
       "  'murderous': False,\n",
       "  'everyday': False,\n",
       "  'tremendous': False,\n",
       "  'wry': False,\n",
       "  'unforced': False,\n",
       "  'future': False,\n",
       "  'inspired': False,\n",
       "  'cruel': False,\n",
       "  'irresistible': False,\n",
       "  'volatile': False,\n",
       "  'higher': False,\n",
       "  'wide': False,\n",
       "  'fuzzy': False,\n",
       "  'ironic': False,\n",
       "  'liberal': False,\n",
       "  'angry': False,\n",
       "  'exotic': False,\n",
       "  'marginal': False,\n",
       "  'epic': False,\n",
       "  'fourth': False,\n",
       "  'eric': False,\n",
       "  'tale': False,\n",
       "  'lightweight': False,\n",
       "  'audacious': False,\n",
       "  'responsible': False,\n",
       "  'straightforward': False,\n",
       "  'glorious': False,\n",
       "  'valuable': False,\n",
       "  'appropriate': False,\n",
       "  'meaningful': False,\n",
       "  'didactic': False,\n",
       "  'serial': False,\n",
       "  'redundant': False,\n",
       "  'racial': False,\n",
       "  'deadpan': False,\n",
       "  'sensational': False,\n",
       "  'concerned': False,\n",
       "  'parable': False,\n",
       "  'contrived': False,\n",
       "  'smarter': False,\n",
       "  'unable': False,\n",
       "  'trashy': False,\n",
       "  'tiny': False,\n",
       "  'acceptable': False,\n",
       "  'martial': False,\n",
       "  'buoyant': False,\n",
       "  'somber': False,\n",
       "  'cerebral': False,\n",
       "  'neat': False,\n",
       "  'animal': False,\n",
       "  'tepid': False,\n",
       "  'frantic': False,\n",
       "  'conservative': False,\n",
       "  'laugh-out-loud': False,\n",
       "  'attractive': False,\n",
       "  'first-rate': False,\n",
       "  'dreadful': False,\n",
       "  'glossy': False,\n",
       "  'bottom': False,\n",
       "  'former': False,\n",
       "  'big-screen': False,\n",
       "  'john': False,\n",
       "  'mean-spirited': False,\n",
       "  'nonsensical': False,\n",
       "  'vapid': False,\n",
       "  'pointless': False,\n",
       "  'lifeless': False,\n",
       "  'listless': False,\n",
       "  'stiff': False,\n",
       "  'ill-conceived': False,\n",
       "  'monotonous': False,\n",
       "  'hypnotic': False,\n",
       "  'novel': False,\n",
       "  'invincible': False,\n",
       "  'morvern': False,\n",
       "  'sudden': False,\n",
       "  'richer': False,\n",
       "  'incredible': False,\n",
       "  'riveting': False,\n",
       "  'educational': False,\n",
       "  'sardonic': False,\n",
       "  'double': False,\n",
       "  'holocaust': False,\n",
       "  'nervous': False,\n",
       "  'absurdist': False,\n",
       "  'give': False,\n",
       "  'magical': False,\n",
       "  'todd': False,\n",
       "  'direct': False,\n",
       "  'genre': False,\n",
       "  'pat': False,\n",
       "  'ethnic': False,\n",
       "  'quest': False,\n",
       "  'international': False,\n",
       "  'fast-paced': False,\n",
       "  'dogtown': False,\n",
       "  'wet': False,\n",
       "  'artful': False,\n",
       "  'well-written': False,\n",
       "  'feels': False,\n",
       "  'challenging': False,\n",
       "  'further': False,\n",
       "  'local': False,\n",
       "  'unfamiliar': False,\n",
       "  'life-affirming': False,\n",
       "  'inherent': False,\n",
       "  'spirited': False,\n",
       "  'sobering': False,\n",
       "  'committed': False,\n",
       "  'melancholy': False,\n",
       "  'fast': False,\n",
       "  'wholesome': False,\n",
       "  'numerous': False,\n",
       "  'idiosyncratic': False,\n",
       "  'youthful': False,\n",
       "  'lucky': False,\n",
       "  'dazzling': False,\n",
       "  'pleasurable': False,\n",
       "  'ambiguous': False,\n",
       "  'es': False,\n",
       "  'handsome': False,\n",
       "  'familial': False,\n",
       "  'ready': False,\n",
       "  'uplifting': False,\n",
       "  'determined': False,\n",
       "  'laugh': False,\n",
       "  'clunky': False,\n",
       "  'unsatisfying': False,\n",
       "  'patient': False,\n",
       "  'appealing': False,\n",
       "  'very': False,\n",
       "  'western': False,\n",
       "  'pointed': False,\n",
       "  'nuanced': False,\n",
       "  'amiable': False,\n",
       "  'fantasy': False,\n",
       "  'adventurous': False,\n",
       "  'magnificent': False,\n",
       "  'ii': False,\n",
       "  'accurate': False,\n",
       "  'fake': False,\n",
       "  'onscreen': False,\n",
       "  'mad': False,\n",
       "  'undone': False,\n",
       "  'naturalistic': False,\n",
       "  'legal': False,\n",
       "  'seductive': False,\n",
       "  'opaque': False,\n",
       "  'complicated': False,\n",
       "  'muddled': False,\n",
       "  'elusive': False,\n",
       "  'existential': False,\n",
       "  'daytime': False,\n",
       "  'dirty': False,\n",
       "  'verbal': False,\n",
       "  'confident': False,\n",
       "  'top-notch': False,\n",
       "  'indie': False,\n",
       "  '90-minute': False,\n",
       "  'ryan': False,\n",
       "  'magic': False,\n",
       "  'crucial': False,\n",
       "  'highest': False,\n",
       "  'generous': False,\n",
       "  'observant': False,\n",
       "  'daily': False,\n",
       "  'enigmatic': False,\n",
       "  'anachronistic': False,\n",
       "  'climactic': False,\n",
       "  'enthusiastic': False,\n",
       "  'unbelievable': False,\n",
       "  'uncanny': False,\n",
       "  'encouraging': False,\n",
       "  'inexplicable': False,\n",
       "  'sophomoric': False,\n",
       "  'upper': False,\n",
       "  'flawed': False,\n",
       "  'initial': False,\n",
       "  'revelatory': False,\n",
       "  'live': False,\n",
       "  'exaggerated': False,\n",
       "  'adequate': False,\n",
       "  'dubious': False,\n",
       "  'so-so': False,\n",
       "  'stereotypical': False,\n",
       "  'crude': False,\n",
       "  'erotic': False,\n",
       "  'mechanical': False,\n",
       "  'sluggish': False,\n",
       "  'distasteful': False,\n",
       "  'eager': False,\n",
       "  'flimsy': False,\n",
       "  'unconvincing': False,\n",
       "  'fewer': False,\n",
       "  'unlikable': False,\n",
       "  'talky': False,\n",
       "  'brisk': False,\n",
       "  'funeral': False,\n",
       "  'unassuming': False,\n",
       "  'likeable': False,\n",
       "  'truly': False,\n",
       "  'startling': False,\n",
       "  'hong': False,\n",
       "  'archival': False,\n",
       "  'unpretentious': False,\n",
       "  'fellow': False,\n",
       "  'steady': False,\n",
       "  'sound': False,\n",
       "  'timely': False,\n",
       "  'invaluable': False,\n",
       "  'u': False,\n",
       "  'lavish': False,\n",
       "  'grown-up': False,\n",
       "  'tongue-in-cheek': False,\n",
       "  'offbeat': False,\n",
       "  'reflective': False,\n",
       "  'perceptive': False,\n",
       "  'boisterous': False,\n",
       "  'metaphorical': False,\n",
       "  'self-deprecating': False,\n",
       "  'fleeting': False,\n",
       "  'phenomenal': False,\n",
       "  'shaky': False,\n",
       "  'mary': False,\n",
       "  'hokey': False,\n",
       "  'lean': False,\n",
       "  'elizabeth': False,\n",
       "  'sweetest': False,\n",
       "  'graceful': False,\n",
       "  'slapstick': False,\n",
       "  'forceful': False,\n",
       "  'punch-drunk': False,\n",
       "  'symbolic': False,\n",
       "  'tight': False,\n",
       "  'bogus': False,\n",
       "  'favorite': False,\n",
       "  'indulgent': False,\n",
       "  'expressive': False,\n",
       "  'nonstop': False,\n",
       "  'informative': False,\n",
       "  'high-tech': False,\n",
       "  'distinct': False,\n",
       "  'robin': False,\n",
       "  'innocuous': False,\n",
       "  'topical': False,\n",
       "  'acting': False,\n",
       "  'lively': False,\n",
       "  'scottish': False,\n",
       "  'literal': False,\n",
       "  'eventual': False,\n",
       "  'stuart': False,\n",
       "  'unbearable': False,\n",
       "  'demented': False,\n",
       "  'awesome': False,\n",
       "  'tortured': False,\n",
       "  'clinical': False,\n",
       "  'stronger': False,\n",
       "  'haunting': False,\n",
       "  'german': False,\n",
       "  'austin': False,\n",
       "  'military': False,\n",
       "  'edgy': False,\n",
       "  'eddie': False,\n",
       "  'xxx': False,\n",
       "  'specific': False,\n",
       "  'gratuitous': False,\n",
       "  'lurid': False,\n",
       "  'rabbit-proof': False,\n",
       "  'gory': False,\n",
       "  'visible': False,\n",
       "  'crystal': False,\n",
       "  'primitive': False,\n",
       "  'vast': False,\n",
       "  'collective': False,\n",
       "  'proper': False,\n",
       "  'truthful': False,\n",
       "  'passable': False,\n",
       "  'scorsese': False,\n",
       "  'escapist': False,\n",
       "  '20th': False,\n",
       "  'tony': False,\n",
       "  'uma': False,\n",
       "  'brian': False,\n",
       "  'minimalist': False,\n",
       "  'economical': False,\n",
       "  'n': False,\n",
       "  'terrorist': False,\n",
       "  'african': False,\n",
       "  'unconventional': False,\n",
       "  'crisp': False,\n",
       "  'modern-day': False,\n",
       "  'silent': False,\n",
       "  'primary': False,\n",
       "  'deft': False,\n",
       "  'anne': False,\n",
       "  'phony': False,\n",
       "  'sumptuous': False,\n",
       "  'palpable': False,\n",
       "  'objective': False,\n",
       "  'useless': False,\n",
       "  'uncomfortable': False,\n",
       "  'tom': False,\n",
       "  'friday': False,\n",
       "  'stylized': False,\n",
       "  'sketchy': False,\n",
       "  'would-be': False,\n",
       "  'genial': False,\n",
       "  'thick': False,\n",
       "  'pale': False,\n",
       "  'lesser': False,\n",
       "  'yiddish': False,\n",
       "  'cohesive': False,\n",
       "  'suburban': False,\n",
       "  'halloween': False,\n",
       "  'extra': False,\n",
       "  'action-packed': False,\n",
       "  'fat': False,\n",
       "  'leigh': False,\n",
       "  'reluctant': False,\n",
       "  'consistent': False,\n",
       "  'shapeless': False,\n",
       "  'inner-city': False,\n",
       "  'severe': False,\n",
       "  'mental': False,\n",
       "  'kevin': False,\n",
       "  'fancy': False,\n",
       "  'moving': False,\n",
       "  'definitive': False,\n",
       "  'notable': False,\n",
       "  'longest': False,\n",
       "  'impenetrable': False,\n",
       "  'corny': False,\n",
       "  'computer-generated': False,\n",
       "  'eloquent': False,\n",
       "  'forced': False,\n",
       "  'rote': False,\n",
       "  'farcical': False,\n",
       "  'immediate': False,\n",
       "  'idiotic': False,\n",
       "  'absurd': False,\n",
       "  'competent': False,\n",
       "  'shoddy': False,\n",
       "  'musty': False,\n",
       "  'incomprehensible': False,\n",
       "  'irritating': False,\n",
       "  'preachy': False,\n",
       "  'witless': False,\n",
       "  'annoying': False,\n",
       "  'half-baked': False,\n",
       "  'dumbed-down': False,\n",
       "  'wooden': False,\n",
       "  'half-hearted': False,\n",
       "  'radical': False,\n",
       "  'episodic': False,\n",
       "  'lower': False,\n",
       "  'unfortunate': False,\n",
       "  'unwatchable': False,\n",
       "  'ripe': False,\n",
       "  'overblown': False,\n",
       "  \"'the\": False,\n",
       "  ...},\n",
       " 'pos')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good enough. And that's it, our featuresets.\n",
    "\n",
    "Now one important last step, let's shuffle them up before sending them through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "import random\n",
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train the dataset using Naive Bayes Classifier</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there're many Bayes Classifiers, and Naive Bayes Classifier is propably the most simple one as you can probably guess from the name.\n",
    "\n",
    "Naive Bayes is a probabilistic classifier. On a high level explaination, the classifier will take an input of texts, break the texts down into single words, compute the likeliness of each word (in the bags-of-words) independently and then compute the likelihood of the whole texts altogether, and give us result - either pos or neg. \n",
    "\n",
    "The computation of the Naive Bayes classifiers is fairly simple, therefore it's fast, and considered as an easy one to scale. This material is by far the best in-depth explanation for Naive Bayes Classifier: http://web.stanford.edu/~jurafsky/slp3/4.pdf (Thanks Zak for sharing!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our work. Let's split our ready-to-go featuresets into a training set and a testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#rule of thumb 80/20\n",
    "training_set = featuresets[:8530]\n",
    "testing_set = featuresets[8530:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>training_set</b> is picked for the machine to do the training. Here, the machine knows if a review is negative or positive.\n",
    "\n",
    "<b>testing_set</b> is picked for the machine to do the testing. Here, the machine doesn't actually know the result.\n",
    "What the accuracy method actually does here is give the machine a data set withou any result, let the machine guess itself, \n",
    "and then test against it, and finally return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "accuracy = nltk.classify.accuracy(classifier, testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how our module does in terms of accuracy. Note that the accuracy can change slightly each time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.33645735707591"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "accuracy_percentage = accuracy*100\n",
    "accuracy_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called supervised machine learning, because we're showing the machine data, and telling it \"hey, this data is positive,\" or \"this data is negative.\" Then, after that training is done, we show the machine some new data and ask the computer, based on what we taught the computer before, what the computer thinks the category of the new data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     20.3 : 1.0\n",
      "                    warm = True              pos : neg    =     18.9 : 1.0\n",
      "                  boring = True              neg : pos    =     17.1 : 1.0\n",
      "                powerful = True              pos : neg    =     13.8 : 1.0\n",
      "                 routine = True              neg : pos    =     13.7 : 1.0\n",
      "                    loud = True              neg : pos    =     13.0 : 1.0\n",
      "                    flat = True              neg : pos    =     12.6 : 1.0\n",
      "                  unique = True              pos : neg    =     12.3 : 1.0\n",
      "              unexpected = True              pos : neg    =     11.6 : 1.0\n",
      "              delightful = True              pos : neg    =     11.6 : 1.0\n",
      "              refreshing = True              pos : neg    =     11.6 : 1.0\n",
      "               wonderful = True              pos : neg    =     10.6 : 1.0\n",
      "                   minor = True              pos : neg    =      9.6 : 1.0\n",
      "               affecting = True              pos : neg    =      9.6 : 1.0\n",
      "               realistic = True              pos : neg    =      9.6 : 1.0\n",
      "                  stupid = True              neg : pos    =      9.4 : 1.0\n",
      "                annoying = True              neg : pos    =      9.0 : 1.0\n",
      "                touching = True              pos : neg    =      9.0 : 1.0\n",
      "                delicate = True              pos : neg    =      9.0 : 1.0\n",
      "                  tender = True              pos : neg    =      9.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "#check the most informative words in deciding whether a review is either positive or negative. interesting.\n",
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test our module manually</h3>\n",
    "\n",
    "Lets create a function, that takes any texts as an input, and see how it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return classifier.classify(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "sentiment(\"It was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "sentiment(\"I hate it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "sentiment(\"AMZN do you like it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Some comments</h4>\n",
    "\n",
    "- the method relies on if specific words appear more in neg/pos reviews and predicts based on words\n",
    "- neutral sentences tend to be classified as negative\n",
    "- Zak please add more :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save feature sets and module</h3>\n",
    "\n",
    "Now we have our module all set up. The next important thing is to save all of these above steps in a .py file, so that we could later import it and use it somewhere else. \n",
    "\n",
    "\n",
    "Luckily we won't have to copy and run everything again in the .py file. We can skip some steps thanks to Pickle - a package for Python object serialization. Pickle will help us zip our progress in a .pickle file, so that we can load and run it fast later. \n",
    "\n",
    "\n",
    "To install pickle, use the command line { pip install pickle } or { pip3 install pickle }. If these don't work, hmm... google it.\n",
    "\n",
    "\n",
    "The object we'll pickle here are:\n",
    "- documents\n",
    "- word_features\n",
    "\n",
    "In your working folder, create a folder \"pickled\" to save the .pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro-nltk.ipynb\n",
    "\n",
    "import pickle\n",
    "\n",
    "save_documents = open(\"pickled/documents.pickle\", \"wb\") #create and open a pickle file, allow writing access\n",
    "pickle.dump(documents, save_documents) #put the classifier in the pickle file\n",
    "save_documents.close()  #close the file and done!\n",
    "\n",
    "save_word_features = open(\"pickled/word_features.pickle\", \"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's all done for the our intro-nltk.ipynb file now.\n",
    "\n",
    "In your working folder, create a file sentiment_mod.py.\n",
    "\n",
    "Go ahead, put in the following code, these are just the work we did above. We're now done saving the module in sentiment_mod.py too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_mod.py\n",
    "\n",
    "import pickle\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "#get training data\n",
    "documents_f = open(\"pickled/documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "#check frequencies\n",
    "word_features5k_f = open(\"pickled/word_features.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = nltk.word_tokenize(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words) \n",
    "    \n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev,category) in documents]\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "#positive data example\n",
    "training_set = featuresets[:8530]\n",
    "testing_set = featuresets[8530:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy: \", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return classifier.classify(feats)\n",
    "\n",
    "print(sentiment(\"It was awesome!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. GET LIVE TWEETS FROM TWITTER API</h3>\n",
    "\n",
    "Twitter streaming API allows us to connect to 1% of all tweets, that is 1% 500 million tweets per day - still actually a lot of tweets. \n",
    "\n",
    "First, you gotta be able to connect to the API using your twitter account and get the following info:\n",
    "-ckey\n",
    "-csecret\n",
    "-atoken\n",
    "-asecret\n",
    "\n",
    "Unfortunately, I can't share with you my keys. But here's a helpful tutorial to help you get yours: https://pythonprogramming.net/twitter-api-streaming-tweets-python-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're done, create a file called stream.py in your working foler and insert the following code\n",
    "\n",
    "Don't run the code on your jupyter notebook\n",
    "\n",
    "- Connect to Twitter API to get access to live tweets\n",
    "- \n",
    "- Save all of those tweets in a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my API access token\n",
    "#I HAVE TO REMEMBER TO HIDE MY TOKENS LATER\n",
    "\n",
    "# stream.py\n",
    "\n",
    "from tweepy import Stream, OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import sentiment_mod as s\n",
    "\n",
    "ckey=\"ASfenRJcyi4b8r9NjPVzFex8m\"\n",
    "csecret=\"WMYSrpfA82DQHNpiTPB6XFkjZgMxFphG1hu4wXKLIoZCZm3aW1\"\n",
    "atoken=\"798767325772029952-lcpNI5IOTozzniYRXblWHcfNYYUJoTa\"\n",
    "asecret=\"fqWAC8kGtzU1CBrxAcwtdd68VADpwZFf5Y9ivsi00qmkb\"\n",
    "\n",
    "\n",
    "class listener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        #Connect to Twitter API to get access to live tweets\n",
    "        all_data = json.loads(data)\n",
    "        tweet = all_data[\"text\"]\n",
    "        \n",
    "        #Get all of the tweets that has the given keyword (check the last line)\n",
    "        sentiment_value = s.sentiment(tweet)\n",
    "        print(tweet)\n",
    "        print(sentiment_value)\n",
    "\n",
    "        #Save them tweets all in a .txt file\n",
    "        output = open(\"out.txt\",\"a\")\n",
    "        output.write(sentiment_value)\n",
    "        output.write('\\n')\n",
    "        output.close()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "auth = OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "\n",
    "twitterStream = Stream(auth, listener())\n",
    "twitterStream.filter(track=[\"election\"]) #<----- change the word to any word that your curious about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we got our stream going. Here're some notes though, you gotta pay attention too:\n",
    "- Twitter does limit your connection, it's a free API after all. Just google the error code that gives you. Or most of the time I just waited for awhile and run my stream.py again. \n",
    "- Our next step is to visualize based on the results we get from the stream, so you will want to have the stream.py file up and running, while we also run the graph.py that we're going to talk about now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Graphing Live Twitter Sentiment Analysis</h2>\n",
    "\n",
    "Using Matplotlib, a very popular tool for visualization,I wwon't explain much how it works here but the idea is that we have the results save in the out.txt file, each result is separated by a new line. Just open your out.txt file and check if you need to.\n",
    "\n",
    "Our plan to graph the trend is like this:\n",
    "- if positive, the line will go up 1. \n",
    "- if negative, the line will go down 1.\n",
    "\n",
    "Simple enough, go ahead and create a file called graph.py in your working folder and insert the following code\n",
    "\n",
    "<b>Keep the stream.py file running parallel with graph.py</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "import time\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "def animate(i):\n",
    "    pullData = open(\"out.txt\",\"r\").read()\n",
    "    lines = pullData.split('\\n')\n",
    "\n",
    "    xar = []\n",
    "    yar = []\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    for l in lines[-200:]:\n",
    "        x += 1\n",
    "        if \"pos\" in l:\n",
    "            y += 1\n",
    "        elif \"neg\" in l:\n",
    "            y -= 1\n",
    "\n",
    "        xar.append(x)\n",
    "        yar.append(y)\n",
    "        \n",
    "    ax1.clear()\n",
    "    ax1.plot(xar,yar)\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, animate, interval=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew. My part's done and there are several things we can ellaborate based on this simple projects. Here are some of my ideas for us:\n",
    "- Use other datasets\n",
    "- Mix and test some variables: for example, word types in the featuresets, the ratio of training set and testing set\n",
    "- Use some other classifiers in scikit-learn (if you are familiar with scikit-learn), test the result for each classifier, and maybe build a combined classifier?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
